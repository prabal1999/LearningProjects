{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a951c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the one_hot method used for converting the words of a sentence into one-hot vectors\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4fa593",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['the glass of milk',\n",
    "       'the glass of juice',\n",
    "       'the cup of tea',\n",
    "       'I am a good boy',\n",
    "       'understand the meaning of words',\n",
    "       'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd786f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the size of vocabulary which we are going to use\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee68665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2097, 6875, 9796, 2442],\n",
       " [2097, 6875, 9796, 4242],\n",
       " [2097, 9650, 9796, 3764],\n",
       " [1749, 1498, 324, 1, 8287],\n",
       " [8153, 2097, 8350, 9796, 3650],\n",
       " [3188, 8353, 8604, 1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating the onw-hot vectors of the words of every sentence in sent list\n",
    "one_hot_repr = [one_hot(word, voc_size) for word in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cafa9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "\n",
    "#pad_sequences are necessary for making the size of all the sentences we are using for training the model, this helps----\n",
    "#------us in getting a good embedded matrix for further training(feature representation)\n",
    "\n",
    "#Ebedding is a method present in keras which helps us in generating the feature or wrod embedding representation of out input data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f2abd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 2097, 6875, 9796, 2442],\n",
       "       [   0,    0,    0,    0, 2097, 6875, 9796, 4242],\n",
       "       [   0,    0,    0,    0, 2097, 9650, 9796, 3764],\n",
       "       [   0,    0,    0, 1749, 1498,  324,    1, 8287],\n",
       "       [   0,    0,    0, 8153, 2097, 8350, 9796, 3650],\n",
       "       [   0,    0,    0,    0, 3188, 8353, 8604,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for pad_sequences we need to input the size length we want in our sentences that we are using as input for training our model\n",
    "sent_size = 8;\n",
    "sentences = pad_sequences(one_hot_repr, padding='pre', maxlen=sent_size)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6987ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential is used for generating the layers for our model, using this we can stack the input, the hidden and the output----\n",
    "#----layers just by using the add() method\n",
    "\n",
    "#then an embedding layer is added using the emebedding method which takes three input parameters that are-- the vocabulary----\n",
    "#----size, the dimensions we want for our words vectors and the size after we used the padding sequences.\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, 10, input_length=sent_size))\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b71924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00449574 -0.02616431 -0.01248996 -0.01470381 -0.00940485  0.04032949\n",
      "  -0.007067   -0.01534583  0.01628545  0.04230345]\n",
      " [ 0.00449574 -0.02616431 -0.01248996 -0.01470381 -0.00940485  0.04032949\n",
      "  -0.007067   -0.01534583  0.01628545  0.04230345]\n",
      " [ 0.00449574 -0.02616431 -0.01248996 -0.01470381 -0.00940485  0.04032949\n",
      "  -0.007067   -0.01534583  0.01628545  0.04230345]\n",
      " [ 0.00449574 -0.02616431 -0.01248996 -0.01470381 -0.00940485  0.04032949\n",
      "  -0.007067   -0.01534583  0.01628545  0.04230345]\n",
      " [ 0.02542799 -0.01585108  0.011471    0.01014336 -0.01902751 -0.0185219\n",
      "  -0.03822808 -0.03382152 -0.01332867 -0.04298564]\n",
      " [-0.00638924  0.04017304  0.0042269   0.0229478   0.02816166 -0.02336757\n",
      "   0.0327201  -0.02471956 -0.0087612   0.01212581]\n",
      " [ 0.04570487 -0.01560326  0.01725436 -0.02492828  0.00868527 -0.04438327\n",
      "  -0.03342296 -0.0338583  -0.00961246  0.01321789]\n",
      " [ 0.01364756  0.01538545 -0.00623403 -0.04564184 -0.01856705  0.03535527\n",
      "   0.00667905  0.01694177  0.00879922 -0.00689225]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(sentences)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d571f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
